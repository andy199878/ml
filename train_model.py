import nltk
from nltk.corpus import movie_reviews
import random
import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_curve
import xgboost as xgb
import pickle
import json
import sqlite3
from datetime import datetime
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éäº’å‹•å¼å¾Œç«¯
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import os
warnings.filterwarnings('ignore')

class EnhancedSentimentModelPipeline:
    """å®Œå…¨ç›¸å®¹æ–°ç‰ˆapp_enhanced.pyçš„æƒ…æ„Ÿåˆ†ææ¨¡å‹ç®¡é“"""
    
    def __init__(self):
        self.models = {}
        self.vectorizer = None
        self.best_model = None
        self.model_performances = {}
        self.db_path = 'sentiment_analysis.db'
        
    def setup_database(self):
        """å»ºç«‹å®Œå…¨ç›¸å®¹çš„æ•¸æ“šåº«è¡¨çµæ§‹"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # é æ¸¬è¨˜éŒ„è¡¨ - æ·»åŠ latencyå’Œuser_feedbackæ¬„ä½
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS predictions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                text TEXT NOT NULL,
                prediction INTEGER NOT NULL,
                confidence REAL NOT NULL,
                model_name TEXT NOT NULL,
                latency REAL DEFAULT 0.0,
                user_feedback INTEGER DEFAULT NULL,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # æ¨¡å‹æ€§èƒ½è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS model_performance (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                model_name TEXT NOT NULL,
                accuracy REAL NOT NULL,
                precision_pos REAL NOT NULL,
                precision_neg REAL NOT NULL,
                recall_pos REAL NOT NULL,
                recall_neg REAL NOT NULL,
                f1_score REAL NOT NULL,
                auc_score REAL NOT NULL,
                training_date DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # A/Bæ¸¬è©¦è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS ab_test_results (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                model_a TEXT NOT NULL,
                model_b TEXT NOT NULL,
                text TEXT NOT NULL,
                prediction_a INTEGER NOT NULL,
                prediction_b INTEGER NOT NULL,
                confidence_a REAL NOT NULL,
                confidence_b REAL NOT NULL,
                user_feedback INTEGER,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
        print("âœ“ æ•¸æ“šåº«è¡¨å»ºç«‹å®Œæˆ (ç›¸å®¹app_enhanced.py)")
    
    def load_and_preprocess_data(self):
        """è¼‰å…¥ä¸¦é è™•ç†æ•¸æ“š"""
        print("ğŸ“š è¼‰å…¥é›»å½±è©•è«–æ•¸æ“š...")
        
        # ä¸‹è¼‰NLTKæ•¸æ“š
        try:
            nltk.download("movie_reviews", quiet=True)
            nltk.download("punkt", quiet=True)
            nltk.download("stopwords", quiet=True)
            print("âœ“ NLTK æ•¸æ“šæº–å‚™å®Œæˆ")
        except Exception as e:
            print(f"âš  NLTK æ•¸æ“šä¸‹è¼‰å¤±æ•—: {e}")
        
        # è¼‰å…¥æ•¸æ“š
        documents = [(list(movie_reviews.words(fileid)), category)
                     for category in movie_reviews.categories()
                     for fileid in movie_reviews.fileids(category)]
        
        random.seed(42)
        np.random.seed(42)
        random.shuffle(documents)
        
        # é è™•ç†
        texts = []
        labels = []
        
        for words, label in documents:
            text = " ".join(words).lower()
            # éæ¿¾å¤ªçŸ­çš„æ–‡æœ¬
            if len(text.split()) > 10:
                texts.append(text)
                labels.append(1 if label == "pos" else 0)
        
        print(f"è³‡æ–™é‡: {len(texts)} ç­†")
        print(f"æ­£é¢: {sum(labels)} ç­† ({sum(labels)/len(labels)*100:.1f}%)")
        print(f"è² é¢: {len(labels) - sum(labels)} ç­† ({(len(labels) - sum(labels))/len(labels)*100:.1f}%)")
        
        return texts, labels
    
    def prepare_features(self, texts, labels):
        """ç‰¹å¾µå·¥ç¨‹"""
        print("ğŸ”§ é€²è¡Œç‰¹å¾µå·¥ç¨‹...")
        
        # ä½¿ç”¨TF-IDFå‘é‡åŒ– - é‡å°appæ€§èƒ½å„ªåŒ–
        self.vectorizer = TfidfVectorizer(
            max_features=5000,
            stop_words='english',
            ngram_range=(1, 3),
            min_df=3,
            max_df=0.8,
            sublinear_tf=True,
            use_idf=True,
            smooth_idf=True,
            norm='l2'
        )
        
        X = self.vectorizer.fit_transform(texts)
        
        # åˆ†å‰²æ•¸æ“š
        X_train, X_test, y_train, y_test = train_test_split(
            X, labels, test_size=0.2, random_state=42, stratify=labels
        )
        
        print(f"è¨“ç·´é›†: {X_train.shape[0]} ç­†")
        print(f"æ¸¬è©¦é›†: {X_test.shape[0]} ç­†")
        print(f"ç‰¹å¾µç¶­åº¦: {X_train.shape[1]}")
        
        return X_train, X_test, y_train, y_test
    
    def initialize_models(self):
        """åˆå§‹åŒ–å¤šç¨®æ¨¡å‹ - é‡å°ç”Ÿç”¢ç’°å¢ƒå„ªåŒ–"""
        print("ğŸ¤– åˆå§‹åŒ–å¤šç¨®æ©Ÿå™¨å­¸ç¿’æ¨¡å‹...")
        
        self.models = {
            'best_model': LogisticRegression(  # ä¸»è¦æ¨¡å‹
                max_iter=3000,
                random_state=42,
                class_weight='balanced',
                solver='liblinear'
            ),
            'Logistic_Regression': LogisticRegression(
                max_iter=3000,
                random_state=42,
                class_weight='balanced',
                solver='liblinear'
            ),
            'Random_Forest': RandomForestClassifier(
                n_estimators=100,
                random_state=42,
                class_weight='balanced',
                n_jobs=-1  # åŠ é€Ÿè¨“ç·´
            ),
            'SVM': SVC(
                probability=True,
                random_state=42,
                class_weight='balanced',
                kernel='linear'  # æ›´å¿«çš„ç·šæ€§æ ¸
            ),
            'XGBoost': xgb.XGBClassifier(
                random_state=42,
                eval_metric='logloss',
                n_jobs=-1  # åŠ é€Ÿè¨“ç·´
            )
        }
        
        return self.models
    
    def train_and_evaluate_models(self, X_train, X_test, y_train, y_test):
        """è¨“ç·´ä¸¦è©•ä¼°æ‰€æœ‰æ¨¡å‹"""
        print("ğŸƒâ€â™‚ï¸ é–‹å§‹è¨“ç·´å’Œè©•ä¼°æ¨¡å‹...")
        
        results = {}
        
        for name, model in self.models.items():
            print(f"\nè¨“ç·´ {name}...")
            
            try:
                # è¨“ç·´æ¨¡å‹
                model.fit(X_train, y_train)
                
                # é æ¸¬
                y_pred = model.predict(X_test)
                y_pred_proba = model.predict_proba(X_test)[:, 1]
                
                # è©•ä¼°æŒ‡æ¨™
                accuracy = model.score(X_test, y_test)
                auc_score = roc_auc_score(y_test, y_pred_proba)
                
                # åˆ†é¡å ±å‘Š
                report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)
                
                # äº¤å‰é©—è­‰
                cv_scores = cross_val_score(model, X_train, y_train, cv=3, scoring='f1_macro')
                
                results[name] = {
                    'model': model,
                    'accuracy': accuracy,
                    'auc_score': auc_score,
                    'precision_pos': report.get('1', {}).get('precision', 0),
                    'precision_neg': report.get('0', {}).get('precision', 0),
                    'recall_pos': report.get('1', {}).get('recall', 0),
                    'recall_neg': report.get('0', {}).get('recall', 0),
                    'f1_score': report.get('macro avg', {}).get('f1-score', 0),
                    'cv_mean': cv_scores.mean(),
                    'cv_std': cv_scores.std(),
                    'y_pred': y_pred,
                    'y_pred_proba': y_pred_proba
                }
                
                print(f"  æº–ç¢ºç‡: {accuracy:.4f}")
                print(f"  AUCåˆ†æ•¸: {auc_score:.4f}")
                print(f"  F1åˆ†æ•¸: {report.get('macro avg', {}).get('f1-score', 0):.4f}")
                print(f"  äº¤å‰é©—è­‰: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}")
                
            except Exception as e:
                print(f"  âŒ è¨“ç·´ {name} å¤±æ•—: {e}")
                continue
        
        self.model_performances = results
        return results
    
    def select_best_model(self, results):
        """é¸æ“‡æœ€ä½³æ¨¡å‹"""
        print("ğŸ† é¸æ“‡æœ€ä½³æ¨¡å‹...")
        
        # ç¶œåˆè©•åˆ† (æº–ç¢ºç‡ + F1åˆ†æ•¸ + AUCåˆ†æ•¸) / 3
        best_score = 0
        best_model_name = None
        
        for name, metrics in results.items():
            if name == 'best_model':  # è·³éé‡è¤‡çš„best_model
                continue
                
            composite_score = (metrics['accuracy'] + metrics['f1_score'] + metrics['auc_score']) / 3
            print(f"{name}: ç¶œåˆè©•åˆ† {composite_score:.4f}")
            
            if composite_score > best_score:
                best_score = composite_score
                best_model_name = name
        
        if best_model_name:
            self.best_model = results[best_model_name]['model']
            # åŒæ™‚æ›´æ–°best_modelæ¢ç›®
            self.models['best_model'] = self.best_model
            print(f"âœ“ æœ€ä½³æ¨¡å‹: {best_model_name} (è©•åˆ†: {best_score:.4f})")
            return best_model_name, self.best_model
        else:
            print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„æœ€ä½³æ¨¡å‹")
            return None, None
    
    def save_model_performance_to_db(self, results):
        """å°‡æ¨¡å‹æ€§èƒ½ä¿å­˜åˆ°æ•¸æ“šåº«"""
        print("ğŸ’¾ ä¿å­˜æ¨¡å‹æ€§èƒ½åˆ°æ•¸æ“šåº«...")
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            for name, metrics in results.items():
                cursor.execute('''
                    INSERT INTO model_performance 
                    (model_name, accuracy, precision_pos, precision_neg, 
                     recall_pos, recall_neg, f1_score, auc_score)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    name,
                    float(metrics['accuracy']),
                    float(metrics['precision_pos']),
                    float(metrics['precision_neg']),
                    float(metrics['recall_pos']),
                    float(metrics['recall_neg']),
                    float(metrics['f1_score']),
                    float(metrics['auc_score'])
                ))
            
            conn.commit()
            conn.close()
            print("âœ“ æ¨¡å‹æ€§èƒ½å·²ä¿å­˜åˆ°æ•¸æ“šåº«")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜åˆ°æ•¸æ“šåº«å¤±æ•—: {e}")
    
    def create_visualizations(self, results, y_test):
        """å‰µå»ºè¦–è¦ºåŒ–åœ–è¡¨"""
        print("ğŸ“Š å‰µå»ºæ¨¡å‹æ¯”è¼ƒè¦–è¦ºåŒ–...")
        
        try:
            # ç¢ºä¿staticç›®éŒ„å­˜åœ¨
            os.makedirs('static', exist_ok=True)
            
            # éæ¿¾æœ‰æ•ˆçµæœ
            valid_results = {name: metrics for name, metrics in results.items() 
                           if 'y_pred' in metrics and metrics['y_pred'] is not None}
            
            if not valid_results:
                print("âš  æ²’æœ‰æœ‰æ•ˆçš„çµæœç”¨æ–¼è¦–è¦ºåŒ–")
                return
            
            # 1. æ¨¡å‹æ€§èƒ½æ¯”è¼ƒ
            fig, axes = plt.subplots(2, 2, figsize=(15, 12))
            fig.suptitle('æ¨¡å‹æ€§èƒ½æ¯”è¼ƒ', fontsize=16)
            
            models = list(valid_results.keys())
            accuracy_scores = [valid_results[name]['accuracy'] for name in models]
            f1_scores = [valid_results[name]['f1_score'] for name in models]
            auc_scores = [valid_results[name]['auc_score'] for name in models]
            
            # æº–ç¢ºç‡æ¯”è¼ƒ
            axes[0, 0].bar(models, accuracy_scores, color='skyblue')
            axes[0, 0].set_title('æº–ç¢ºç‡æ¯”è¼ƒ')
            axes[0, 0].set_ylabel('æº–ç¢ºç‡')
            axes[0, 0].tick_params(axis='x', rotation=45)
            
            # F1åˆ†æ•¸æ¯”è¼ƒ
            axes[0, 1].bar(models, f1_scores, color='lightgreen')
            axes[0, 1].set_title('F1åˆ†æ•¸æ¯”è¼ƒ')
            axes[0, 1].set_ylabel('F1åˆ†æ•¸')
            axes[0, 1].tick_params(axis='x', rotation=45)
            
            # AUCåˆ†æ•¸æ¯”è¼ƒ
            axes[1, 0].bar(models, auc_scores, color='orange')
            axes[1, 0].set_title('AUCåˆ†æ•¸æ¯”è¼ƒ')
            axes[1, 0].set_ylabel('AUCåˆ†æ•¸')
            axes[1, 0].tick_params(axis='x', rotation=45)
            
            # ç¶œåˆè©•åˆ†
            composite_scores = [(accuracy_scores[i] + f1_scores[i] + auc_scores[i])/3 
                              for i in range(len(models))]
            axes[1, 1].bar(models, composite_scores, color='purple')
            axes[1, 1].set_title('ç¶œåˆè©•åˆ†')
            axes[1, 1].set_ylabel('ç¶œåˆè©•åˆ†')
            axes[1, 1].tick_params(axis='x', rotation=45)
            
            plt.tight_layout()
            plt.savefig('static/model_comparison.png', dpi=300, bbox_inches='tight')
            plt.close()
            
            # 2. æ··æ·†çŸ©é™£ - åªé¡¯ç¤ºå‰4å€‹æ¨¡å‹
            display_models = list(valid_results.items())[:4]
            fig, axes = plt.subplots(2, 2, figsize=(15, 12))
            fig.suptitle('å„æ¨¡å‹æ··æ·†çŸ©é™£', fontsize=16)
            
            for i, (name, metrics) in enumerate(display_models):
                row, col = i // 2, i % 2
                cm = confusion_matrix(y_test, metrics['y_pred'])
                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[row, col])
                axes[row, col].set_title(f'{name}')
                axes[row, col].set_xlabel('é æ¸¬å€¼')
                axes[row, col].set_ylabel('å¯¦éš›å€¼')
            
            # å¦‚æœæ¨¡å‹å°‘æ–¼4å€‹ï¼Œéš±è—å¤šé¤˜çš„å­åœ–
            for i in range(len(display_models), 4):
                row, col = i // 2, i % 2
                axes[row, col].set_visible(False)
            
            plt.tight_layout()
            plt.savefig('static/confusion_matrices.png', dpi=300, bbox_inches='tight')
            plt.close()
            
            print("âœ“ è¦–è¦ºåŒ–åœ–è¡¨å·²ç”Ÿæˆä¸¦ä¿å­˜åˆ° static/ ç›®éŒ„")
            
        except Exception as e:
            print(f"âŒ è¦–è¦ºåŒ–ç”Ÿæˆå¤±æ•—: {e}")
    
    def save_models_for_app(self, best_model_name):
        """ä¿å­˜æ¨¡å‹æ–‡ä»¶ä»¥ä¾›app_enhanced.pyä½¿ç”¨"""
        print("ğŸ’¾ ä¿å­˜æ¨¡å‹å’Œå‘é‡åŒ–å™¨...")
        
        try:
            # ä¿å­˜æœ€ä½³æ¨¡å‹ (app_enhanced.pyå„ªå…ˆè¼‰å…¥)
            if self.best_model:
                pickle.dump(self.best_model, open("best_model.pkl", "wb"))
                print("âœ“ æœ€ä½³æ¨¡å‹å·²ä¿å­˜ç‚º best_model.pkl")
            
            # ä¿å­˜å‘é‡åŒ–å™¨
            if self.vectorizer:
                pickle.dump(self.vectorizer, open("vectorizer.pkl", "wb"))
                print("âœ“ å‘é‡åŒ–å™¨å·²ä¿å­˜ç‚º vectorizer.pkl")
            
            # ä¿å­˜æ‰€æœ‰æ¨¡å‹ (ä¾›A/Bæ¸¬è©¦ä½¿ç”¨)
            if self.models:
                pickle.dump(self.models, open("all_models.pkl", "wb"))
                print("âœ“ æ‰€æœ‰æ¨¡å‹å·²ä¿å­˜ç‚º all_models.pkl")
            
            # ç›¸å®¹æ€§ï¼šä¹Ÿä¿å­˜ç‚ºåŸä¾†çš„åç¨±
            if self.best_model:
                pickle.dump(self.best_model, open("model.pkl", "wb"))
                print("âœ“ ç›¸å®¹æ€§æ¨¡å‹å·²ä¿å­˜ç‚º model.pkl")
            
            # ä¿å­˜æ¨¡å‹æ€§èƒ½å ±å‘Š (ä¾›å„€è¡¨æ¿ä½¿ç”¨)
            if self.model_performances:
                serializable_performances = {}
                for name, metrics in self.model_performances.items():
                    serializable_performances[name] = {
                        k: float(v) if isinstance(v, (np.integer, np.floating)) else v
                        for k, v in metrics.items()
                        if k not in ['model', 'y_pred', 'y_pred_proba']
                    }
                
                report_data = {
                    'best_model': best_model_name,
                    'performances': serializable_performances,
                    'training_date': datetime.now().isoformat(),
                    'model_files': {
                        'best_model': 'best_model.pkl',
                        'vectorizer': 'vectorizer.pkl',
                        'all_models': 'all_models.pkl'
                    }
                }
                
                with open("model_performance_report.json", "w", encoding='utf-8') as f:
                    json.dump(report_data, f, indent=2, ensure_ascii=False)
                
                print("âœ“ æ€§èƒ½å ±å‘Šå·²ä¿å­˜ç‚º model_performance_report.json")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹ä¿å­˜å¤±æ•—: {e}")
            return False
        
        return True
    
    def test_app_compatibility(self):
        """æ¸¬è©¦èˆ‡app_enhanced.pyçš„ç›¸å®¹æ€§"""
        print("ğŸ§ª æ¸¬è©¦èˆ‡app_enhanced.pyçš„ç›¸å®¹æ€§...")
        
        test_cases = [
            "This movie is absolutely amazing and fantastic!",
            "Terrible film, complete waste of time.",
            "Pretty decent movie, not bad at all.",
            "I hate this boring and awful film."
        ]
        
        try:
            # æ¸¬è©¦æ¨¡å‹è¼‰å…¥
            if os.path.exists("best_model.pkl") and os.path.exists("vectorizer.pkl"):
                model = pickle.load(open("best_model.pkl", "rb"))
                vectorizer = pickle.load(open("vectorizer.pkl", "rb"))
                print("âœ“ æ¨¡å‹æ–‡ä»¶è¼‰å…¥æˆåŠŸ")
                
                # æ¸¬è©¦é æ¸¬åŠŸèƒ½
                for i, text in enumerate(test_cases, 1):
                    vec = vectorizer.transform([text])
                    prediction = model.predict(vec)[0]
                    probability = model.predict_proba(vec)[0]
                    confidence = max(probability)
                    
                    sentiment = "positive" if prediction == 1 else "negative"
                    print(f"  æ¸¬è©¦ {i}: {sentiment} (ä¿¡å¿ƒåº¦: {confidence:.3f})")
                
                print("âœ“ é æ¸¬åŠŸèƒ½æ¸¬è©¦é€šé")
                return True
                
            else:
                print("âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨")
                return False
                
        except Exception as e:
            print(f"âŒ ç›¸å®¹æ€§æ¸¬è©¦å¤±æ•—: {e}")
            return False
    
    def run_full_pipeline(self):
        """åŸ·è¡Œå®Œæ•´çš„è¨“ç·´ç®¡é“"""
        print("="*70)
        print("ğŸš€ é–‹å§‹åŸ·è¡Œå¢å¼·ç‰ˆæƒ…æ„Ÿåˆ†ææ¨¡å‹è¨“ç·´ç®¡é“")
        print("ğŸ¯ é‡å° app_enhanced.py å®Œå…¨å„ªåŒ–")
        print("="*70)
        
        try:
            # 1. è¨­ç½®æ•¸æ“šåº«
            self.setup_database()
            
            # 2. è¼‰å…¥ä¸¦é è™•ç†æ•¸æ“š
            texts, labels = self.load_and_preprocess_data()
            
            # 3. ç‰¹å¾µå·¥ç¨‹
            X_train, X_test, y_train, y_test = self.prepare_features(texts, labels)
            
            # 4. åˆå§‹åŒ–æ¨¡å‹
            self.initialize_models()
            
            # 5. è¨“ç·´å’Œè©•ä¼°æ¨¡å‹
            results = self.train_and_evaluate_models(X_train, X_test, y_train, y_test)
            
            if not results:
                print("âŒ æ²’æœ‰æˆåŠŸè¨“ç·´çš„æ¨¡å‹")
                return False
            
            # 6. é¸æ“‡æœ€ä½³æ¨¡å‹
            best_model_name, _ = self.select_best_model(results)
            
            if not best_model_name:
                print("âŒ æœªèƒ½é¸æ“‡æœ€ä½³æ¨¡å‹")
                return False
            
            # 7. ä¿å­˜æ€§èƒ½åˆ°æ•¸æ“šåº«
            self.save_model_performance_to_db(results)
            
            # 8. å‰µå»ºè¦–è¦ºåŒ–
            self.create_visualizations(results, y_test)
            
            # 9. ä¿å­˜æ¨¡å‹æ–‡ä»¶
            if not self.save_models_for_app(best_model_name):
                return False
            
            # 10. æ¸¬è©¦ç›¸å®¹æ€§
            if not self.test_app_compatibility():
                return False
            
            print("\n" + "="*70)
            print("âœ… è¨“ç·´ç®¡é“åŸ·è¡ŒæˆåŠŸï¼")
            print(f"ğŸ† æœ€ä½³æ¨¡å‹: {best_model_name}")
            print("ğŸ“ ç”Ÿæˆæ–‡ä»¶:")
            print("  âœ“ best_model.pkl (ä¸»è¦æ¨¡å‹)")
            print("  âœ“ model.pkl (ç›¸å®¹æ€§)")
            print("  âœ“ vectorizer.pkl (å‘é‡åŒ–å™¨)")
            print("  âœ“ all_models.pkl (A/Bæ¸¬è©¦ç”¨)")
            print("  âœ“ model_performance_report.json (æ€§èƒ½å ±å‘Š)")
            print("  âœ“ static/*.png (è¦–è¦ºåŒ–åœ–è¡¨)")
            print("  âœ“ sentiment_analysis.db (æ•¸æ“šåº«)")
            print("\nğŸ‰ ç¾åœ¨å¯ä»¥åŸ·è¡Œ app_enhanced.py å•Ÿå‹•ç”Ÿç”¢ç´šæ‡‰ç”¨ï¼")
            print("="*70)
            
            return True
            
        except Exception as e:
            print(f"âŒ è¨“ç·´ç®¡é“åŸ·è¡Œå¤±æ•—: {e}")
            return False

def main():
    """ä¸»å‡½æ•¸"""
    pipeline = EnhancedSentimentModelPipeline()
    
    print("æ­¡è¿ä½¿ç”¨å¢å¼·ç‰ˆæƒ…æ„Ÿåˆ†ææ¨¡å‹è¨“ç·´ç³»çµ±")
    print("æ­¤ç‰ˆæœ¬å®Œå…¨ç›¸å®¹ app_enhanced.py")
    print("-" * 70)
    
    success = pipeline.run_full_pipeline()
    
    if success:
        print("\nğŸŠ è¨“ç·´å®Œæˆï¼æ¥ä¸‹ä¾†å¯ä»¥:")
        print("1. åŸ·è¡Œ: python app_enhanced.py")
        print("2. æˆ–ä½¿ç”¨: ./run.sh")
        print("3. è¨ªå•: http://localhost:5000")
        
        # æä¾›å¿«é€Ÿå•Ÿå‹•é¸é …
        user_input = input("\næ˜¯å¦ç«‹å³å•Ÿå‹•æ‡‰ç”¨ï¼Ÿ(y/n): ")
        if user_input.lower() in ['y', 'yes']:
            try:
                os.system("python app_enhanced.py")
            except KeyboardInterrupt:
                print("\næ‡‰ç”¨å·²åœæ­¢")
    else:
        print("\nâŒ è¨“ç·´å¤±æ•—ï¼Œè«‹æª¢æŸ¥éŒ¯èª¤ä¿¡æ¯")

if __name__ == "__main__":
    main()